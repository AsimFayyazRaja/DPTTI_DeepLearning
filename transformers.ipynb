{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformers.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPY3bRCNEHXMT54f0ZI8Evv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"6POmdeJ10A6L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644650705546,"user_tz":-300,"elapsed":4133,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"82993dec-7550-4337-ad13-d94fdcfecf5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#use this https://keras.io/examples/nlp/text_classification_with_transformer/\n","\n","# also https://alvinntnu.github.io/NTNU_ENC2045_LECTURES/nlp/dl-transformers-keras.html"],"metadata":{"id":"NIxzp_KGKtua"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"a_3Z9QT0Ktwn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd drive/MyDrive/Sapienza/DL"],"metadata":{"id":"XPgacE6d0CfX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644650705547,"user_tz":-300,"elapsed":7,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"a8f178ef-4bfc-4be1-d084-8907ed498185"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Sapienza/DL\n"]}]},{"cell_type":"code","source":["import pickle\n","import pandas as pd\n","import numpy as np\n","import json\n","import itertools\n","import gensim\n","\n","\n","path=\"SEMEVAL-2021-task6-corpus/data/\"\n","\n","with open('training_task1_labels.pkl', 'rb') as handle:\n","    train_labs = pickle.load(handle)\n","\n","with open('training_task1_features_w2v.pkl', 'rb') as handle:\n","    train_feats = pickle.load(handle)\n","\n","with open('training_task1_all_labels.pkl', 'rb') as handle:\n","    all_labels = pickle.load(handle)\n","\n","with open('dev_task1_labels.pkl', 'rb') as handle:\n","    dev_labs = pickle.load(handle)\n","\n","with open('dev_task1_features_w2v.pkl', 'rb') as handle:\n","    dev_feats = pickle.load(handle)\n","\n","with open('test_task1_labels.pkl', 'rb') as handle:\n","    test_labs = pickle.load(handle)\n","\n","with open('test_task1_features_w2v.pkl', 'rb') as handle:\n","    test_feats = pickle.load(handle)\n","\n"],"metadata":{"id":"kHAhDMWR0Chu","executionInfo":{"status":"ok","timestamp":1644650708279,"user_tz":-300,"elapsed":2176,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["n_classes=23"],"metadata":{"id":"SU2wCAYM0CkW","executionInfo":{"status":"ok","timestamp":1644650709649,"user_tz":-300,"elapsed":2,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import Normalizer\n","norm=Normalizer()\n","train_feats=norm.fit_transform(np.reshape(train_feats,(len(train_feats),-1)))\n","dev_feats=norm.transform(np.reshape(dev_feats,(len(dev_feats),-1)))\n","test_feats=norm.transform(np.reshape(test_feats,(len(test_feats),-1)))"],"metadata":{"id":"A-epEZEDijnG","executionInfo":{"status":"ok","timestamp":1644648572064,"user_tz":-300,"elapsed":501,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train_feats=np.reshape(train_feats,(len(train_feats),32,256))\n","dev_feats=np.reshape(dev_feats,(len(dev_feats),32,256))\n","test_feats=np.reshape(test_feats,(len(test_feats),32,256))"],"metadata":{"id":"ABnj-OMdr8j8","executionInfo":{"status":"ok","timestamp":1644648572064,"user_tz":-300,"elapsed":3,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_feats, dev_feats, train_labs, dev_labs\n","X_train=np.array(X_train)\n","X_test=np.array(X_test)\n","y_train=np.array(y_train)\n","y_test=np.array(y_test)"],"metadata":{"id":"aZS4oLrshjYD","executionInfo":{"status":"ok","timestamp":1644648572065,"user_tz":-300,"elapsed":4,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"XoXBR2HPhjav","executionInfo":{"status":"ok","timestamp":1644648572546,"user_tz":-300,"elapsed":2,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"BHVCNw38rvw_","executionInfo":{"status":"ok","timestamp":1644648573036,"user_tz":-300,"elapsed":2,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"nSk2f5t4rvzY","executionInfo":{"status":"ok","timestamp":1644648573835,"user_tz":-300,"elapsed":3,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WJk3Rw9ijpe","executionInfo":{"status":"ok","timestamp":1644648575215,"user_tz":-300,"elapsed":3,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"fe272c9a-8638-4a17-9c7c-b16f23c468d5"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(688, 32, 256)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Normalization and Attention\n","    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n","    x = layers.MultiHeadAttention( # add multi head attention layer\n","        key_dim=head_size, num_heads=num_heads, dropout=dropout\n","    )(x, x)\n","    x = layers.Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Feed Forward Part\n","    x = layers.LayerNormalization(epsilon=1e-6)(res)\n","    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x) # 1D convolution for the signals\n","    x = layers.Dropout(dropout)(x)\n","    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n","    return x + res\n","\n","def build_model(\n","    input_shape,\n","    head_size,\n","    num_heads,\n","    ff_dim,\n","    num_transformer_blocks,\n","    mlp_units,\n","    dropout=0,\n","    mlp_dropout=0,\n","):\n","    inputs = keras.Input(shape=input_shape)\n","    x = inputs\n","    for _ in range(num_transformer_blocks): # make multiple transformer blocks\n","        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n","\n","    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x) # do global pooling to add dense network at the end\n","    for dim in mlp_units: \n","        x = layers.Dense(dim, activation=\"relu\",name='dense1')(x)\n","        x = layers.Dropout(mlp_dropout)(x)\n","    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n","    return keras.Model(inputs, outputs)\n","\n"],"metadata":{"id":"usVAMyRs0Cmr","executionInfo":{"status":"ok","timestamp":1644650720222,"user_tz":-300,"elapsed":6890,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["input_shape = X_train.shape[1:]\n","\n","model = build_model( # build the transformer model\n","    input_shape,\n","    head_size=64,\n","    num_heads=8,\n","    ff_dim=64,\n","    num_transformer_blocks=4,\n","    mlp_units=[256],\n","    mlp_dropout=0.2,\n","    dropout=0.2,\n",")\n"],"metadata":{"id":"bEXBHAyw0Cot","executionInfo":{"status":"ok","timestamp":1644648609201,"user_tz":-300,"elapsed":1739,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model.compile(\n","    loss=\"categorical_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","    metrics=[\"categorical_accuracy\"],\n",")\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bxOVGaL7iRmJ","executionInfo":{"status":"ok","timestamp":1644648612222,"user_tz":-300,"elapsed":349,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"db7003b8-8d3a-4c6e-e97e-5a2c75cd1675"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 32, 256)]    0           []                               \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 32, 256)     512         ['input_1[0][0]']                \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 32, 256)     526080      ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," dropout (Dropout)              (None, 32, 256)      0           ['multi_head_attention[0][0]']   \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 32, 256)     0           ['dropout[0][0]',                \n"," da)                                                              'input_1[0][0]']                \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 32, 256)     512         ['tf.__operators__.add[0][0]']   \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 32, 64)       16448       ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 32, 64)       0           ['conv1d[0][0]']                 \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, 32, 256)      16640       ['dropout_1[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 32, 256)     0           ['conv1d_1[0][0]',               \n"," mbda)                                                            'tf.__operators__.add[0][0]']   \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 32, 256)     512         ['tf.__operators__.add_1[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 32, 256)     526080      ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 32, 256)      0           ['multi_head_attention_1[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, 32, 256)     0           ['dropout_2[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_1[0][0]'] \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 32, 256)     512         ['tf.__operators__.add_2[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_2 (Conv1D)              (None, 32, 64)       16448       ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 32, 64)       0           ['conv1d_2[0][0]']               \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, 32, 256)      16640       ['dropout_3[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, 32, 256)     0           ['conv1d_3[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_2[0][0]'] \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, 32, 256)     512         ['tf.__operators__.add_3[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, 32, 256)     526080      ['layer_normalization_4[0][0]',  \n"," eadAttention)                                                    'layer_normalization_4[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 32, 256)      0           ['multi_head_attention_2[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_4 (TFOpLa  (None, 32, 256)     0           ['dropout_4[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_3[0][0]'] \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, 32, 256)     512         ['tf.__operators__.add_4[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_4 (Conv1D)              (None, 32, 64)       16448       ['layer_normalization_5[0][0]']  \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 32, 64)       0           ['conv1d_4[0][0]']               \n","                                                                                                  \n"," conv1d_5 (Conv1D)              (None, 32, 256)      16640       ['dropout_5[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_5 (TFOpLa  (None, 32, 256)     0           ['conv1d_5[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_4[0][0]'] \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, 32, 256)     512         ['tf.__operators__.add_5[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_3 (MultiH  (None, 32, 256)     526080      ['layer_normalization_6[0][0]',  \n"," eadAttention)                                                    'layer_normalization_6[0][0]']  \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 32, 256)      0           ['multi_head_attention_3[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_6 (TFOpLa  (None, 32, 256)     0           ['dropout_6[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_5[0][0]'] \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, 32, 256)     512         ['tf.__operators__.add_6[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_6 (Conv1D)              (None, 32, 64)       16448       ['layer_normalization_7[0][0]']  \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 32, 64)       0           ['conv1d_6[0][0]']               \n","                                                                                                  \n"," conv1d_7 (Conv1D)              (None, 32, 256)      16640       ['dropout_7[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_7 (TFOpLa  (None, 32, 256)     0           ['conv1d_7[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_6[0][0]'] \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 32)          0           ['tf.__operators__.add_7[0][0]'] \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," dense1 (Dense)                 (None, 256)          8448        ['global_average_pooling1d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 256)          0           ['dense1[0][0]']                 \n","                                                                                                  \n"," dense (Dense)                  (None, 23)           5911        ['dropout_8[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 2,255,127\n","Trainable params: 2,255,127\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n","\n","history=model.fit( # train the model\n","    X_train,\n","    y_train,\n","    epochs=200,\n","    batch_size=16,\n","    validation_data=(X_test,y_test),\n","    callbacks=callbacks,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kIfRe_P4iRom","executionInfo":{"status":"ok","timestamp":1644649567694,"user_tz":-300,"elapsed":952803,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"244c2394-6b4c-450f-85e8-b44ef8a4029e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","43/43 [==============================] - 15s 275ms/step - loss: 6.0530 - categorical_accuracy: 0.1134 - val_loss: 6.7998 - val_categorical_accuracy: 0.0476\n","Epoch 2/200\n","43/43 [==============================] - 11s 259ms/step - loss: 5.9912 - categorical_accuracy: 0.1032 - val_loss: 6.7324 - val_categorical_accuracy: 0.0476\n","Epoch 3/200\n","43/43 [==============================] - 11s 261ms/step - loss: 5.9313 - categorical_accuracy: 0.1032 - val_loss: 6.6683 - val_categorical_accuracy: 0.0476\n","Epoch 4/200\n","43/43 [==============================] - 11s 260ms/step - loss: 5.8740 - categorical_accuracy: 0.1032 - val_loss: 6.6059 - val_categorical_accuracy: 0.0476\n","Epoch 5/200\n","43/43 [==============================] - 12s 268ms/step - loss: 5.8185 - categorical_accuracy: 0.1032 - val_loss: 6.5465 - val_categorical_accuracy: 0.0476\n","Epoch 6/200\n","43/43 [==============================] - 12s 271ms/step - loss: 5.7651 - categorical_accuracy: 0.1032 - val_loss: 6.4896 - val_categorical_accuracy: 0.0476\n","Epoch 7/200\n","43/43 [==============================] - 12s 264ms/step - loss: 5.7133 - categorical_accuracy: 0.1032 - val_loss: 6.4344 - val_categorical_accuracy: 0.0476\n","Epoch 8/200\n","43/43 [==============================] - 11s 261ms/step - loss: 5.6631 - categorical_accuracy: 0.1032 - val_loss: 6.3808 - val_categorical_accuracy: 0.0476\n","Epoch 9/200\n","43/43 [==============================] - 11s 260ms/step - loss: 5.6155 - categorical_accuracy: 0.1032 - val_loss: 6.3299 - val_categorical_accuracy: 0.0476\n","Epoch 10/200\n","43/43 [==============================] - 11s 260ms/step - loss: 5.5692 - categorical_accuracy: 0.1032 - val_loss: 6.2809 - val_categorical_accuracy: 0.0476\n","Epoch 11/200\n","43/43 [==============================] - 11s 258ms/step - loss: 5.5243 - categorical_accuracy: 0.1032 - val_loss: 6.2319 - val_categorical_accuracy: 0.0476\n","Epoch 12/200\n","43/43 [==============================] - 11s 259ms/step - loss: 5.4809 - categorical_accuracy: 0.1032 - val_loss: 6.1866 - val_categorical_accuracy: 0.0476\n","Epoch 13/200\n","43/43 [==============================] - 11s 261ms/step - loss: 5.4401 - categorical_accuracy: 0.1032 - val_loss: 6.1425 - val_categorical_accuracy: 0.0476\n","Epoch 14/200\n","43/43 [==============================] - 11s 264ms/step - loss: 5.4004 - categorical_accuracy: 0.1032 - val_loss: 6.1006 - val_categorical_accuracy: 0.0476\n","Epoch 15/200\n","43/43 [==============================] - 11s 266ms/step - loss: 5.3623 - categorical_accuracy: 0.1032 - val_loss: 6.0604 - val_categorical_accuracy: 0.0476\n","Epoch 16/200\n","43/43 [==============================] - 12s 290ms/step - loss: 5.3257 - categorical_accuracy: 0.1032 - val_loss: 6.0219 - val_categorical_accuracy: 0.0476\n","Epoch 17/200\n","43/43 [==============================] - 11s 259ms/step - loss: 5.2902 - categorical_accuracy: 0.1032 - val_loss: 5.9841 - val_categorical_accuracy: 0.0476\n","Epoch 18/200\n","43/43 [==============================] - 11s 256ms/step - loss: 5.2562 - categorical_accuracy: 0.1032 - val_loss: 5.9481 - val_categorical_accuracy: 0.0476\n","Epoch 19/200\n","43/43 [==============================] - 11s 260ms/step - loss: 5.2238 - categorical_accuracy: 0.1032 - val_loss: 5.9148 - val_categorical_accuracy: 0.0476\n","Epoch 20/200\n","43/43 [==============================] - 11s 262ms/step - loss: 5.1926 - categorical_accuracy: 0.1032 - val_loss: 5.8820 - val_categorical_accuracy: 0.0476\n","Epoch 21/200\n","43/43 [==============================] - 11s 262ms/step - loss: 5.1627 - categorical_accuracy: 0.1032 - val_loss: 5.8505 - val_categorical_accuracy: 0.0476\n","Epoch 22/200\n","43/43 [==============================] - 11s 265ms/step - loss: 5.1340 - categorical_accuracy: 0.1032 - val_loss: 5.8207 - val_categorical_accuracy: 0.0476\n","Epoch 23/200\n","43/43 [==============================] - 11s 263ms/step - loss: 5.1064 - categorical_accuracy: 0.1032 - val_loss: 5.7913 - val_categorical_accuracy: 0.0476\n","Epoch 24/200\n","43/43 [==============================] - 11s 260ms/step - loss: 5.0800 - categorical_accuracy: 0.1032 - val_loss: 5.7635 - val_categorical_accuracy: 0.0476\n","Epoch 25/200\n","43/43 [==============================] - 11s 260ms/step - loss: 5.0545 - categorical_accuracy: 0.1032 - val_loss: 5.7380 - val_categorical_accuracy: 0.0476\n","Epoch 26/200\n","43/43 [==============================] - 11s 258ms/step - loss: 5.0307 - categorical_accuracy: 0.1032 - val_loss: 5.7127 - val_categorical_accuracy: 0.0476\n","Epoch 27/200\n","43/43 [==============================] - 11s 262ms/step - loss: 5.0073 - categorical_accuracy: 0.1032 - val_loss: 5.6892 - val_categorical_accuracy: 0.0476\n","Epoch 28/200\n","43/43 [==============================] - 11s 264ms/step - loss: 4.9850 - categorical_accuracy: 0.1032 - val_loss: 5.6664 - val_categorical_accuracy: 0.0476\n","Epoch 29/200\n","43/43 [==============================] - 11s 259ms/step - loss: 4.9642 - categorical_accuracy: 0.1032 - val_loss: 5.6447 - val_categorical_accuracy: 0.0476\n","Epoch 30/200\n","43/43 [==============================] - 11s 263ms/step - loss: 4.9437 - categorical_accuracy: 0.1032 - val_loss: 5.6245 - val_categorical_accuracy: 0.0476\n","Epoch 31/200\n","43/43 [==============================] - 11s 260ms/step - loss: 4.9245 - categorical_accuracy: 0.1032 - val_loss: 5.6051 - val_categorical_accuracy: 0.0476\n","Epoch 32/200\n","43/43 [==============================] - 11s 261ms/step - loss: 4.9061 - categorical_accuracy: 0.1032 - val_loss: 5.5870 - val_categorical_accuracy: 0.0476\n","Epoch 33/200\n","43/43 [==============================] - 11s 260ms/step - loss: 4.8885 - categorical_accuracy: 0.1032 - val_loss: 5.5685 - val_categorical_accuracy: 0.0476\n","Epoch 34/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.8714 - categorical_accuracy: 0.1032 - val_loss: 5.5511 - val_categorical_accuracy: 0.0476\n","Epoch 35/200\n","43/43 [==============================] - 11s 264ms/step - loss: 4.8551 - categorical_accuracy: 0.1032 - val_loss: 5.5350 - val_categorical_accuracy: 0.0476\n","Epoch 36/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.8399 - categorical_accuracy: 0.1032 - val_loss: 5.5200 - val_categorical_accuracy: 0.0476\n","Epoch 37/200\n","43/43 [==============================] - 11s 261ms/step - loss: 4.8252 - categorical_accuracy: 0.1032 - val_loss: 5.5051 - val_categorical_accuracy: 0.0476\n","Epoch 38/200\n","43/43 [==============================] - 11s 261ms/step - loss: 4.8111 - categorical_accuracy: 0.1032 - val_loss: 5.4916 - val_categorical_accuracy: 0.0476\n","Epoch 39/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.7979 - categorical_accuracy: 0.1032 - val_loss: 5.4784 - val_categorical_accuracy: 0.0476\n","Epoch 40/200\n","43/43 [==============================] - 11s 259ms/step - loss: 4.7851 - categorical_accuracy: 0.1032 - val_loss: 5.4656 - val_categorical_accuracy: 0.0476\n","Epoch 41/200\n","43/43 [==============================] - 11s 259ms/step - loss: 4.7729 - categorical_accuracy: 0.1032 - val_loss: 5.4540 - val_categorical_accuracy: 0.0476\n","Epoch 42/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.7614 - categorical_accuracy: 0.1032 - val_loss: 5.4431 - val_categorical_accuracy: 0.0476\n","Epoch 43/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.7504 - categorical_accuracy: 0.1032 - val_loss: 5.4318 - val_categorical_accuracy: 0.0476\n","Epoch 44/200\n","43/43 [==============================] - 11s 258ms/step - loss: 4.7398 - categorical_accuracy: 0.1032 - val_loss: 5.4218 - val_categorical_accuracy: 0.0476\n","Epoch 45/200\n","43/43 [==============================] - 11s 259ms/step - loss: 4.7299 - categorical_accuracy: 0.1032 - val_loss: 5.4129 - val_categorical_accuracy: 0.0476\n","Epoch 46/200\n","43/43 [==============================] - 11s 261ms/step - loss: 4.7204 - categorical_accuracy: 0.1032 - val_loss: 5.4037 - val_categorical_accuracy: 0.0476\n","Epoch 47/200\n","43/43 [==============================] - 11s 261ms/step - loss: 4.7114 - categorical_accuracy: 0.1032 - val_loss: 5.3953 - val_categorical_accuracy: 0.0476\n","Epoch 48/200\n","43/43 [==============================] - 11s 263ms/step - loss: 4.7028 - categorical_accuracy: 0.1032 - val_loss: 5.3869 - val_categorical_accuracy: 0.0476\n","Epoch 49/200\n","43/43 [==============================] - 11s 263ms/step - loss: 4.6947 - categorical_accuracy: 0.1032 - val_loss: 5.3798 - val_categorical_accuracy: 0.0476\n","Epoch 50/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.6869 - categorical_accuracy: 0.1032 - val_loss: 5.3728 - val_categorical_accuracy: 0.0476\n","Epoch 51/200\n","43/43 [==============================] - 11s 263ms/step - loss: 4.6794 - categorical_accuracy: 0.1032 - val_loss: 5.3663 - val_categorical_accuracy: 0.0476\n","Epoch 52/200\n","43/43 [==============================] - 11s 264ms/step - loss: 4.6724 - categorical_accuracy: 0.1032 - val_loss: 5.3595 - val_categorical_accuracy: 0.0476\n","Epoch 53/200\n","43/43 [==============================] - 11s 259ms/step - loss: 4.6657 - categorical_accuracy: 0.1032 - val_loss: 5.3539 - val_categorical_accuracy: 0.0476\n","Epoch 54/200\n","43/43 [==============================] - 11s 263ms/step - loss: 4.6595 - categorical_accuracy: 0.1032 - val_loss: 5.3481 - val_categorical_accuracy: 0.0476\n","Epoch 55/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.6536 - categorical_accuracy: 0.1032 - val_loss: 5.3429 - val_categorical_accuracy: 0.0476\n","Epoch 56/200\n","43/43 [==============================] - 11s 266ms/step - loss: 4.6481 - categorical_accuracy: 0.1032 - val_loss: 5.3381 - val_categorical_accuracy: 0.0476\n","Epoch 57/200\n","43/43 [==============================] - 11s 263ms/step - loss: 4.6425 - categorical_accuracy: 0.1032 - val_loss: 5.3339 - val_categorical_accuracy: 0.0476\n","Epoch 58/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.6374 - categorical_accuracy: 0.1032 - val_loss: 5.3298 - val_categorical_accuracy: 0.0476\n","Epoch 59/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.6327 - categorical_accuracy: 0.1032 - val_loss: 5.3262 - val_categorical_accuracy: 0.0476\n","Epoch 60/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.6281 - categorical_accuracy: 0.1032 - val_loss: 5.3221 - val_categorical_accuracy: 0.0476\n","Epoch 61/200\n","43/43 [==============================] - 11s 260ms/step - loss: 4.6238 - categorical_accuracy: 0.1032 - val_loss: 5.3189 - val_categorical_accuracy: 0.0476\n","Epoch 62/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.6197 - categorical_accuracy: 0.1032 - val_loss: 5.3161 - val_categorical_accuracy: 0.0476\n","Epoch 63/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.6160 - categorical_accuracy: 0.1032 - val_loss: 5.3131 - val_categorical_accuracy: 0.0476\n","Epoch 64/200\n","43/43 [==============================] - 11s 261ms/step - loss: 4.6126 - categorical_accuracy: 0.1032 - val_loss: 5.3104 - val_categorical_accuracy: 0.0476\n","Epoch 65/200\n","43/43 [==============================] - 11s 263ms/step - loss: 4.6092 - categorical_accuracy: 0.1032 - val_loss: 5.3082 - val_categorical_accuracy: 0.0476\n","Epoch 66/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.6062 - categorical_accuracy: 0.1032 - val_loss: 5.3058 - val_categorical_accuracy: 0.0476\n","Epoch 67/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.6032 - categorical_accuracy: 0.1032 - val_loss: 5.3040 - val_categorical_accuracy: 0.0476\n","Epoch 68/200\n","43/43 [==============================] - 11s 263ms/step - loss: 4.6006 - categorical_accuracy: 0.1032 - val_loss: 5.3024 - val_categorical_accuracy: 0.0476\n","Epoch 69/200\n","43/43 [==============================] - 11s 265ms/step - loss: 4.5979 - categorical_accuracy: 0.1032 - val_loss: 5.3012 - val_categorical_accuracy: 0.0476\n","Epoch 70/200\n","43/43 [==============================] - 11s 266ms/step - loss: 4.5957 - categorical_accuracy: 0.1032 - val_loss: 5.3000 - val_categorical_accuracy: 0.0476\n","Epoch 71/200\n","43/43 [==============================] - 11s 263ms/step - loss: 4.5934 - categorical_accuracy: 0.1032 - val_loss: 5.2988 - val_categorical_accuracy: 0.0476\n","Epoch 72/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.5916 - categorical_accuracy: 0.1032 - val_loss: 5.2975 - val_categorical_accuracy: 0.0476\n","Epoch 73/200\n","43/43 [==============================] - 11s 267ms/step - loss: 4.5895 - categorical_accuracy: 0.1032 - val_loss: 5.2970 - val_categorical_accuracy: 0.0476\n","Epoch 74/200\n","43/43 [==============================] - 11s 265ms/step - loss: 4.5879 - categorical_accuracy: 0.1032 - val_loss: 5.2964 - val_categorical_accuracy: 0.0476\n","Epoch 75/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.5864 - categorical_accuracy: 0.1032 - val_loss: 5.2958 - val_categorical_accuracy: 0.0476\n","Epoch 76/200\n","43/43 [==============================] - 11s 264ms/step - loss: 4.5852 - categorical_accuracy: 0.1032 - val_loss: 5.2960 - val_categorical_accuracy: 0.0476\n","Epoch 77/200\n","43/43 [==============================] - 11s 261ms/step - loss: 4.5837 - categorical_accuracy: 0.1032 - val_loss: 5.2956 - val_categorical_accuracy: 0.0476\n","Epoch 78/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.5827 - categorical_accuracy: 0.1032 - val_loss: 5.2956 - val_categorical_accuracy: 0.0476\n","Epoch 79/200\n","43/43 [==============================] - 11s 261ms/step - loss: 4.5813 - categorical_accuracy: 0.1032 - val_loss: 5.2956 - val_categorical_accuracy: 0.0476\n","Epoch 80/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.5807 - categorical_accuracy: 0.1032 - val_loss: 5.2965 - val_categorical_accuracy: 0.0476\n","Epoch 81/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.5801 - categorical_accuracy: 0.1032 - val_loss: 5.2966 - val_categorical_accuracy: 0.0476\n","Epoch 82/200\n","43/43 [==============================] - 11s 262ms/step - loss: 4.5794 - categorical_accuracy: 0.1032 - val_loss: 5.2970 - val_categorical_accuracy: 0.0476\n","Epoch 83/200\n","43/43 [==============================] - 11s 265ms/step - loss: 4.5788 - categorical_accuracy: 0.1032 - val_loss: 5.2978 - val_categorical_accuracy: 0.0476\n","Epoch 84/200\n","43/43 [==============================] - 11s 265ms/step - loss: 4.5785 - categorical_accuracy: 0.1032 - val_loss: 5.2984 - val_categorical_accuracy: 0.0476\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"jpTjq9zE0Ctc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('training_task1_labels.pkl', 'rb') as handle:\n","    train_labs = pickle.load(handle)\n","\n","with open('training_task1_features.pkl', 'rb') as handle:\n","    train_feats = pickle.load(handle)\n","\n","with open('training_task1_all_labels.pkl', 'rb') as handle:\n","    all_labels = pickle.load(handle)\n","\n","with open('dev_task1_labels.pkl', 'rb') as handle:\n","    dev_labs = pickle.load(handle)\n","\n","with open('dev_task1_features.pkl', 'rb') as handle:\n","    dev_feats = pickle.load(handle)\n","\n","with open('test_task1_labels.pkl', 'rb') as handle:\n","    test_labs = pickle.load(handle)\n","\n","with open('test_task1_features.pkl', 'rb') as handle:\n","    test_feats = pickle.load(handle)\n"],"metadata":{"id":"CvYk58Yd0CwA","executionInfo":{"status":"ok","timestamp":1644650743931,"user_tz":-300,"elapsed":357,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","count_vect = CountVectorizer()\n","X_train_counts = count_vect.fit_transform(train_feats)\n","X_train_counts.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJK-L7EFyM2G","executionInfo":{"status":"ok","timestamp":1644650747258,"user_tz":-300,"elapsed":3,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"f39b6bc7-8a72-4bb4-fde7-2f224373bc90"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(688, 3204)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n","X_train_tf = tf_transformer.transform(X_train_counts)\n","X_train_tf.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibrMontRyM4U","executionInfo":{"status":"ok","timestamp":1644650749049,"user_tz":-300,"elapsed":41,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"ed2d61c6-2dc1-41e3-c7a5-ad6b722cbb91"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(688, 3204)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["tfidf_transformer = TfidfTransformer()\n","X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n","X_train_tfidf.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vP60g_FcyM68","executionInfo":{"status":"ok","timestamp":1644650750737,"user_tz":-300,"elapsed":2,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"b413f1d5-33ad-4b5b-e976-992e887b147c"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(688, 3204)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[""],"metadata":{"id":"HVCZPEm8ynvD","executionInfo":{"status":"ok","timestamp":1644650751686,"user_tz":-300,"elapsed":9,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["dev_counts=count_vect.transform(dev_feats)\n","dev=tfidf_transformer.transform(dev_counts)\n","dev.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ns_DnFgrynxa","executionInfo":{"status":"ok","timestamp":1644650751686,"user_tz":-300,"elapsed":8,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"1bc41ec3-f04e-4353-dc52-bcea9fd9910e"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(63, 3204)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["train_labs[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZ6fXETVyb5N","executionInfo":{"status":"ok","timestamp":1644650751687,"user_tz":-300,"elapsed":7,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"5f34fcba-0af1-4199-97aa-7261df2725ea"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","        0., 0., 0., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n","        1., 0., 0., 0., 0., 1., 0.]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = X_train_tfidf, dev, train_labs, dev_labs\n"],"metadata":{"id":"D5HWbIXQyM9E","executionInfo":{"status":"ok","timestamp":1644650751687,"user_tz":-300,"elapsed":4,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["X_train_tfidf.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJM1GlmyyM_S","executionInfo":{"status":"ok","timestamp":1644650753297,"user_tz":-300,"elapsed":3,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"8d4cf74e-1bdb-44d8-d8c4-e5588820d687"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(688, 3204)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["X_train_tfidf=np.expand_dims(X_train_tfidf.toarray(),axis=2)\n","dev=np.expand_dims(dev.toarray(),axis=2)"],"metadata":{"id":"jMbgmj5TzLUw","executionInfo":{"status":"ok","timestamp":1644650753297,"user_tz":-300,"elapsed":2,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["X_train_tfidf.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9yEiBGpzLXO","executionInfo":{"status":"ok","timestamp":1644650754584,"user_tz":-300,"elapsed":3,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"0c536fbc-912a-4456-af77-7a47f2c8243b"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(688, 3204, 1)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["X_train=np.array(X_train)\n","X_test=np.array(X_test)\n","y_train=np.array(y_train)\n","y_test=np.array(y_test)"],"metadata":{"id":"j3auZhcGyNBo","executionInfo":{"status":"ok","timestamp":1644650755228,"user_tz":-300,"elapsed":2,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"0AoiSk3ayNEG","executionInfo":{"status":"ok","timestamp":1644650574423,"user_tz":-300,"elapsed":2,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["input_shape = X_train_tfidf.shape[1:]\n","\n","model = build_model( # build the transformer model\n","    input_shape,\n","    head_size=8,\n","    num_heads=2,\n","    ff_dim=16,\n","    num_transformer_blocks=2,\n","    mlp_units=[256],\n","    mlp_dropout=0.2,\n","    dropout=0.2,\n",")\n"],"metadata":{"id":"AtQVLDgWzBt_","executionInfo":{"status":"ok","timestamp":1644650769869,"user_tz":-300,"elapsed":1017,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["model.compile(\n","    loss=\"categorical_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","    metrics=[\"categorical_accuracy\"],\n",")\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdXnzXv-zBwd","executionInfo":{"status":"ok","timestamp":1644650773521,"user_tz":-300,"elapsed":431,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"37c7b6ad-ba13-4ab5-f9c4-ed0aaf0163e9"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 3204, 1)]    0           []                               \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 3204, 1)     2           ['input_1[0][0]']                \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 3204, 1)     113         ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," dropout (Dropout)              (None, 3204, 1)      0           ['multi_head_attention[0][0]']   \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 3204, 1)     0           ['dropout[0][0]',                \n"," da)                                                              'input_1[0][0]']                \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 3204, 1)     2           ['tf.__operators__.add[0][0]']   \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 3204, 16)     32          ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 3204, 16)     0           ['conv1d[0][0]']                 \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, 3204, 1)      17          ['dropout_1[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 3204, 1)     0           ['conv1d_1[0][0]',               \n"," mbda)                                                            'tf.__operators__.add[0][0]']   \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 3204, 1)     2           ['tf.__operators__.add_1[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 3204, 1)     113         ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 3204, 1)      0           ['multi_head_attention_1[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, 3204, 1)     0           ['dropout_2[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_1[0][0]'] \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 3204, 1)     2           ['tf.__operators__.add_2[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_2 (Conv1D)              (None, 3204, 16)     32          ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 3204, 16)     0           ['conv1d_2[0][0]']               \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, 3204, 1)      17          ['dropout_3[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, 3204, 1)     0           ['conv1d_3[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_2[0][0]'] \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 3204)        0           ['tf.__operators__.add_3[0][0]'] \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," dense1 (Dense)                 (None, 256)          820480      ['global_average_pooling1d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 256)          0           ['dense1[0][0]']                 \n","                                                                                                  \n"," dense (Dense)                  (None, 23)           5911        ['dropout_4[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 826,723\n","Trainable params: 826,723\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n","\n","history=model.fit( # train the model\n","    X_train_tfidf,\n","    train_labs,\n","    epochs=200,\n","    batch_size=4,\n","    validation_data=(dev,dev_labs),\n","    callbacks=callbacks,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vD8WJTSzBy9","outputId":"55c4e798-3922-4a60-c4c7-c88a2660d521"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","172/172 [==============================] - 985s 6s/step - loss: 1007.8362 - categorical_accuracy: 0.1192 - val_loss: 4723.1816 - val_categorical_accuracy: 0.0476\n","Epoch 2/200\n","172/172 [==============================] - 973s 6s/step - loss: 23881.7344 - categorical_accuracy: 0.1366 - val_loss: 93669.9062 - val_categorical_accuracy: 0.0476\n","Epoch 3/200\n"," 31/172 [====>.........................] - ETA: 12:56 - loss: 86151.4531 - categorical_accuracy: 0.1210"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"f4CTuSYvzB1q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"-qiCKwPzzB32"},"execution_count":null,"outputs":[]}]}